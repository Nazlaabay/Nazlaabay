{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nazlaabay/Nazlaabay/blob/main/Submission%20C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROBLEM C1\n",
        "#\n",
        "# Given two arrays, train a neural network model to match the X to the Y.\n",
        "# Predict the model with new values of X [-2.0, 10.0]\n",
        "# We provide the model prediction, do not change the code.\n",
        "#\n",
        "# The test infrastructure expects a trained model that accepts\n",
        "# an input shape of [1]\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# Please be aware that this is a linear model.\n",
        "# We will test your model with values in a range as defined in the array to make sure your model is linear.\n",
        "#\n",
        "# Desired loss (MSE) < 1e-4\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "def solution_C1():\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    X = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)\n",
        "    Y = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    class CustomCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            if logs['loss'] < 1e-4:\n",
        "                print(\"\\ntarget telah tercapai, stop train !!!\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "    callback = CustomCallback()\n",
        "\n",
        "    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "    model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "    model.fit(X, Y, epochs=1000, )\n",
        "\n",
        "    print(model.predict([-2.0, 10.0]))\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C1()\n",
        "    model.save(\"model_C1.h5\")"
      ],
      "metadata": {
        "id": "l6FcnUx0tioE",
        "outputId": "c35ac484-bb17-42c8-c52e-8c7e615fafe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 1.0825\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9111\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7901\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7038\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6414\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5956\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5612\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5347\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5137\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4965\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4821\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4695\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4582\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4480\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4385\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4295\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4209\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4127\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4047\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3970\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3894\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3821\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3749\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3678\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3610\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3542\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3476\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3411\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3347\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3285\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3223\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3163\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3104\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3046\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2989\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2933\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2879\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2825\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2772\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2720\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2670\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2620\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2571\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2523\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2476\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2430\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2384\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2340\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2296\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2253\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2211\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2170\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2129\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2090\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2051\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2012\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1975\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1938\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1902\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1866\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1831\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1797\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1764\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1731\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1698\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1667\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1636\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1605\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1575\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1546\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1517\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1488\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1461\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1433\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1407\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1380\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1355\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1329\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1305\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1280\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1256\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1233\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1210\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1187\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1165\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1143\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1122\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1101\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1081\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1060\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1041\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1021\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1002\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0983\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0965\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0947\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0929\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0912\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0895\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0878\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0862\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0846\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0830\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0814\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0799\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0784\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0770\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0755\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0741\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0727\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0714\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0700\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0687\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0675\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0662\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0650\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0638\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0626\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0614\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0602\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0591\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0580\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0569\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0559\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0548\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0538\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0528\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0518\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0508\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0499\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0490\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0481\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0472\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0463\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0454\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0446\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0437\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0429\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0421\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0413\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0406\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0398\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0391\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0383\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0376\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0369\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0362\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0355\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0349\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0342\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0336\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0330\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0324\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0317\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0312\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0306\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0300\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0294\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0289\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0284\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0278\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0273\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0268\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0263\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0258\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0253\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0248\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0244\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0239\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0235\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0230\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0226\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0222\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0218\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0214\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0210\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0206\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0202\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0198\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0195\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0191\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0187\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0184\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0180\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0177\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0174\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0170\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0167\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0164\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0161\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0158\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0155\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0152\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0149\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0147\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0144\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0141\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0139\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0136\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0133\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0131\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0128\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0126\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0124\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0121\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0119\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0117\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0115\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0113\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0111\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0108\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0106\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0104\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0102\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0101\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0099\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0097\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0095\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0093\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0092\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0090\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0088\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0087\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0085\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0083\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0082\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0080\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0079\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0077\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0076\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0074\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0073\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0072\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0070\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0069\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0068\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0064\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0062\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0058\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0056\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0055\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0054\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0053\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0052\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0051\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0050\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0049\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0048\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0047\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0046\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0046\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0045\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0044\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0043\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0042\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0041\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0041\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0040\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0039\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0038\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0038\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0037\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0036\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0036\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0035\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0034\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0034\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0033\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0032\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0031\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0031\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0030\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0029\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0028\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0027\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0027\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0026\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0026\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0020\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0019\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0018\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0016\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0016\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0016\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0015\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0014\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0014\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0014\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0014\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0013\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0013\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0013\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0012\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0012\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0012\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0010\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0010\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0010\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.9065e-04\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7216e-04\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.5401e-04\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3620e-04\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.1872e-04\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0157e-04\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8474e-04\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6823e-04\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5202e-04\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3612e-04\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2051e-04\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.0519e-04\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9016e-04\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7541e-04\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6094e-04\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4673e-04\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3279e-04\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1911e-04\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0569e-04\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9252e-04\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7959e-04\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6691e-04\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.5446e-04\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4224e-04\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3025e-04\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1848e-04\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0694e-04\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.9561e-04\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8449e-04\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7358e-04\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.6287e-04\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5236e-04\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4205e-04\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3194e-04\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2201e-04\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1226e-04\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.0270e-04\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9332e-04\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8411e-04\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.7507e-04\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.6620e-04\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5750e-04\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4896e-04\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4058e-04\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.3235e-04\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2428e-04\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1636e-04\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0859e-04\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0097e-04\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9348e-04\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8613e-04\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7893e-04\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7185e-04\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6491e-04\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5810e-04\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5141e-04\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4485e-04\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3842e-04\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3210e-04\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2590e-04\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1982e-04\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1385e-04\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0799e-04\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0224e-04\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9660e-04\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9106e-04\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8563e-04\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8029e-04\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7506e-04\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6993e-04\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6489e-04\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5995e-04\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5509e-04\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5033e-04\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4566e-04\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4107e-04\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3657e-04\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3216e-04\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2782e-04\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2357e-04\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1940e-04\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1530e-04\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1128e-04\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0734e-04\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0347e-04\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9967e-04\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9594e-04\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9228e-04\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8869e-04\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8517e-04\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8172e-04\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7832e-04\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7500e-04\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.7173e-04\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6852e-04\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6538e-04\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6229e-04\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5926e-04\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5629e-04\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5337e-04\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5051e-04\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4770e-04\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4494e-04\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4224e-04\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3958e-04\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3698e-04\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3442e-04\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3191e-04\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2945e-04\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2703e-04\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2466e-04\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2233e-04\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2005e-04\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1781e-04\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1561e-04\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1345e-04\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1133e-04\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0926e-04\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0722e-04\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0521e-04\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0325e-04\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0132e-04\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9432e-05\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.7576e-05\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.5754e-05\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3967e-05\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2213e-05\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0492e-05\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8803e-05\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7145e-05\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5518e-05\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3922e-05\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2356e-05\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0818e-05\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9310e-05\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.7829e-05\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6376e-05\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4950e-05\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3552e-05\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2179e-05\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0831e-05\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9509e-05\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8212e-05\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6938e-05\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5689e-05\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4462e-05\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3259e-05\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2078e-05\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0919e-05\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9782e-05\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8666e-05\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7571e-05\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6496e-05\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5442e-05\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4407e-05\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3392e-05\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2395e-05\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1417e-05\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0457e-05\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9516e-05\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8591e-05\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7684e-05\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6794e-05\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5921e-05\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5064e-05\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4222e-05\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3397e-05\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2586e-05\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1791e-05\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.1011e-05\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0245e-05\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9494e-05\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8757e-05\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8034e-05\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7324e-05\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6627e-05\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5943e-05\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5272e-05\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4614e-05\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3968e-05\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3334e-05\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2712e-05\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2101e-05\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1502e-05\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0914e-05\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0337e-05\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9771e-05\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9215e-05\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8670e-05\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8134e-05\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7609e-05\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7093e-05\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6588e-05\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6092e-05\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5604e-05\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5127e-05\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4658e-05\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4197e-05\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3746e-05\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3302e-05\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2867e-05\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2440e-05\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2022e-05\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1611e-05\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1207e-05\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0811e-05\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0423e-05\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0041e-05\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9667e-05\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9300e-05\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8940e-05\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8586e-05\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8239e-05\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7899e-05\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7565e-05\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7237e-05\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6915e-05\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6600e-05\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6290e-05\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5986e-05\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5687e-05\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5394e-05\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5107e-05\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4825e-05\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4548e-05\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4277e-05\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4010e-05\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3749e-05\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3492e-05\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3240e-05\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2993e-05\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2751e-05\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2513e-05\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2279e-05\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2050e-05\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1825e-05\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1604e-05\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1388e-05\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1175e-05\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0967e-05\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0762e-05\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0561e-05\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0364e-05\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0170e-05\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.9805e-06\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7940e-06\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.6113e-06\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4318e-06\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2558e-06\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0830e-06\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9135e-06\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7472e-06\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5838e-06\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4234e-06\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2663e-06\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1121e-06\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9607e-06\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.8118e-06\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6660e-06\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.5228e-06\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3825e-06\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2447e-06\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1093e-06\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9768e-06\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8464e-06\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7186e-06\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5930e-06\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4701e-06\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3492e-06\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2306e-06\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1144e-06\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0003e-06\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8883e-06\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7783e-06\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6705e-06\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5646e-06\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4606e-06\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.3588e-06\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.2586e-06\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.1605e-06\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0643e-06\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9697e-06\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8769e-06\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7860e-06\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6966e-06\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.6089e-06\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.5229e-06\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4384e-06\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3556e-06\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2743e-06\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1946e-06\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1164e-06\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0394e-06\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9640e-06\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8901e-06\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8175e-06\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7461e-06\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6762e-06\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6076e-06\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5402e-06\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4742e-06\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4092e-06\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3456e-06\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2832e-06\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2219e-06\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1617e-06\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1027e-06\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0448e-06\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9881e-06\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9322e-06\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8775e-06\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8237e-06\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7711e-06\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7193e-06\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6686e-06\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6187e-06\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5699e-06\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5219e-06\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4748e-06\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4286e-06\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3833e-06\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3387e-06\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2951e-06\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2523e-06\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2102e-06\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1690e-06\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1286e-06\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0887e-06\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0498e-06\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0116e-06\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9740e-06\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9371e-06\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9010e-06\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8655e-06\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8307e-06\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7966e-06\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7630e-06\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7301e-06\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6978e-06\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6661e-06\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6350e-06\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6045e-06\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5746e-06\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5451e-06\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5163e-06\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4880e-06\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4602e-06\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4330e-06\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4062e-06\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3800e-06\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3543e-06\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3290e-06\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3042e-06\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2798e-06\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2559e-06\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2325e-06\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2095e-06\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1869e-06\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1648e-06\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1430e-06\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1217e-06\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1008e-06\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0802e-06\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0601e-06\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0402e-06\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0208e-06\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0018e-06\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8311e-07\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6479e-07\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4680e-07\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2915e-07\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1178e-07\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9477e-07\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7803e-07\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.6168e-07\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4560e-07\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.2984e-07\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1439e-07\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9922e-07\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.8421e-07\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6955e-07\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5517e-07\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4113e-07\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2727e-07\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1371e-07\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0039e-07\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8732e-07\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7448e-07\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6189e-07\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4954e-07\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.3738e-07\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2555e-07\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1384e-07\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0234e-07\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9113e-07\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8009e-07\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6924e-07\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5860e-07\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4820e-07\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3798e-07\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2791e-07\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1812e-07\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0839e-07\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9891e-07\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8962e-07\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8049e-07\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7155e-07\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6278e-07\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5412e-07\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4564e-07\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3731e-07\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2913e-07\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2116e-07\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1330e-07\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0558e-07\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9802e-07\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9058e-07\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8329e-07\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7617e-07\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6916e-07\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6226e-07\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5546e-07\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4884e-07\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4235e-07\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3595e-07\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2970e-07\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2354e-07\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1752e-07\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1160e-07\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0577e-07\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0007e-07\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9444e-07\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8897e-07\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8359e-07\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7834e-07\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7313e-07\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6804e-07\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6303e-07\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5811e-07\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5327e-07\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4857e-07\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4388e-07\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3934e-07\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3485e-07\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3045e-07\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2615e-07\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2190e-07\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1775e-07\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1368e-07\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0967e-07\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0574e-07\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0187e-07\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9810e-07\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9440e-07\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9077e-07\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8720e-07\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8373e-07\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8029e-07\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7693e-07\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7364e-07\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7040e-07\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6721e-07\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6408e-07\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6101e-07\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5800e-07\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5505e-07\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5217e-07\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4933e-07\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4654e-07\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4380e-07\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4111e-07\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3849e-07\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3592e-07\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3336e-07\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3088e-07\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2844e-07\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2603e-07\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2368e-07\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2138e-07\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1913e-07\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1689e-07\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1471e-07\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1258e-07\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1048e-07\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0842e-07\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0639e-07\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0441e-07\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0246e-07\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0055e-07\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8678e-08\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6835e-08\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.5030e-08\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3271e-08\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1523e-08\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9820e-08\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.8138e-08\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.6484e-08\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.4873e-08\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3293e-08\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1744e-08\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.0221e-08\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8722e-08\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7256e-08\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5809e-08\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4405e-08\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3002e-08\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1637e-08\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0315e-08\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8992e-08\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7707e-08\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6443e-08\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5206e-08\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3994e-08\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2791e-08\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1607e-08\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0454e-08\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.9329e-08\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.8234e-08\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.7132e-08\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6059e-08\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5012e-08\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3986e-08\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.2972e-08\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1973e-08\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1007e-08\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.0060e-08\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9118e-08\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8205e-08\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.7298e-08\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.6424e-08\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5561e-08\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4700e-08\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3879e-08\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3066e-08\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2265e-08\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1463e-08\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0706e-08\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9935e-08\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9200e-08\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8460e-08\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7740e-08\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7031e-08\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6341e-08\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5664e-08\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4994e-08\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4339e-08\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3699e-08\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3068e-08\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2448e-08\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1847e-08\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1248e-08\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0661e-08\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0093e-08\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9527e-08\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8977e-08\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8435e-08\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7908e-08\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7384e-08\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6877e-08\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6371e-08\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5886e-08\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5406e-08\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4928e-08\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4471e-08\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4007e-08\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3567e-08\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3135e-08\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2690e-08\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2276e-08\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1865e-08\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1449e-08\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1055e-08\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0663e-08\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0278e-08\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9896e-08\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9526e-08\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9165e-08\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8809e-08\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8456e-08\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8120e-08\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7774e-08\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7444e-08\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7120e-08\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6795e-08\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6482e-08\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6178e-08\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5877e-08\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5582e-08\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5286e-08\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5012e-08\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4731e-08\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4453e-08\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4185e-08\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3926e-08\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3665e-08\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3407e-08\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3155e-08\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2914e-08\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2674e-08\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2437e-08\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2205e-08\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1974e-08\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1747e-08\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1536e-08\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1317e-08\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1106e-08\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0898e-08\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0696e-08\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0503e-08\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0304e-08\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0114e-08\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9292e-09\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.7458e-09\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.5617e-09\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3787e-09\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2064e-09\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0357e-09\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.8666e-09\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7050e-09\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5373e-09\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3771e-09\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2214e-09\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0694e-09\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9168e-09\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.7725e-09\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.6225e-09\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4812e-09\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3456e-09\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2094e-09\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0728e-09\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9394e-09\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8091e-09\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.6871e-09\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.5662e-09\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4395e-09\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3160e-09\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1975e-09\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.0840e-09\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.9717e-09\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8609e-09\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7525e-09\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6424e-09\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5360e-09\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4374e-09\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3377e-09\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2407e-09\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1429e-09\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.0477e-09\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.9517e-09\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.8583e-09\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.7714e-09\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6826e-09\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.5947e-09\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.5101e-09\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4277e-09\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3422e-09\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2575e-09\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.1834e-09\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.1038e-09\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0311e-09\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9529e-09\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8816e-09\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8049e-09\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "[[-1.3202429e-04]\n",
            " [ 6.0001426e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROBLEM C2\n",
        "#\n",
        "# Create a classifier for the MNIST Handwritten digit dataset.\n",
        "# The test will expect it to classify 10 classes.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# Desired accuracy AND validation_accuracy > 91%\n",
        "# =============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        accuracy = logs.get('accuracy') or 0.0\n",
        "        val_accuracy = logs.get('val_accuracy') or 0.0\n",
        "        if accuracy > 0.92 and val_accuracy > 0.92:\n",
        "            print(\"\\ntarget telah tercapai, stop train !!!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def solution_C2():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    # NORMALIZE YOUR IMAGE HERE\n",
        "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "    training_images = training_images / 255.0\n",
        "    test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "    test_images = test_images / 255.0\n",
        "\n",
        "    # DEFINE YOUR MODEL HERE\n",
        "    # End with 10 Neuron Dense, activated by softmax\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    callback = CustomCallback()\n",
        "    # COMPILE MODEL HERE\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # TRAIN YOUR MODEL HERE\n",
        "    model.fit(training_images,\n",
        "              training_labels,\n",
        "              validation_data=(test_images, test_labels),\n",
        "              epochs=10,\n",
        "              verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C2()\n",
        "    model.save(\"model_C2.h5\")"
      ],
      "metadata": {
        "id": "uHT5nlXKuOP9",
        "outputId": "80e73abf-34e3-4f3f-a56e-090f6d8bb70e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 65s 34ms/step - loss: 0.1255 - accuracy: 0.9612 - val_loss: 0.0402 - val_accuracy: 0.9862\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.0324 - val_accuracy: 0.9881\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0293 - accuracy: 0.9909 - val_loss: 0.0415 - val_accuracy: 0.9866\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0260 - val_accuracy: 0.9916\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.0274 - val_accuracy: 0.9914\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0254 - val_accuracy: 0.9911\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9902\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0316 - val_accuracy: 0.9908\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0310 - val_accuracy: 0.9921\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0333 - val_accuracy: 0.9926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================================================================\n",
        "# PROBLEM C3\n",
        "#\n",
        "# Build a CNN based classifier for Cats vs Dogs dataset.\n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 72%\n",
        "# ========================================================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        accuracy = logs.get('accuracy') or 0.0\n",
        "        val_accuracy = logs.get('val_accuracy') or 0.0\n",
        "        if accuracy > 0.75 and val_accuracy > 0.75:\n",
        "            print(\"\\ntarget telah tercapai, stop train !!!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def solution_C3():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n",
        "    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n",
        "    local_file = 'cats_and_dogs.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    BASE_DIR = 'data/cats_and_dogs_filtered'\n",
        "    train_dir = os.path.join(BASE_DIR, 'train')\n",
        "    validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        rotation_range=20,\n",
        "        validation_split=0.2)  # YOUR CODE HERE\n",
        "\n",
        "    # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "    # Make sure you used \"binary\"\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        color_mode='rgb',\n",
        "        class_mode='binary',\n",
        "        subset='training')  # YOUR CODE HERE\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        color_mode='rgb',\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    callbacks = CustomCallback()\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=80,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=20,\n",
        "        callbacks=[callbacks],\n",
        "        verbose=2)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C3()\n",
        "    model.save(\"model_C3.h5\")"
      ],
      "metadata": {
        "id": "G_K-aClzuyZG",
        "outputId": "79282985-1409-4de3-8357-c2a37d848dc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "80/80 - 62s - loss: 0.7230 - accuracy: 0.5025 - 62s/epoch - 775ms/step\n",
            "Epoch 2/20\n",
            "80/80 - 59s - loss: 0.6849 - accuracy: 0.5625 - 59s/epoch - 732ms/step\n",
            "Epoch 3/20\n",
            "80/80 - 57s - loss: 0.6589 - accuracy: 0.6275 - 57s/epoch - 718ms/step\n",
            "Epoch 4/20\n",
            "80/80 - 59s - loss: 0.6280 - accuracy: 0.6606 - 59s/epoch - 732ms/step\n",
            "Epoch 5/20\n",
            "80/80 - 61s - loss: 0.5912 - accuracy: 0.6888 - 61s/epoch - 762ms/step\n",
            "Epoch 6/20\n",
            "80/80 - 59s - loss: 0.5806 - accuracy: 0.7019 - 59s/epoch - 740ms/step\n",
            "Epoch 7/20\n",
            "80/80 - 59s - loss: 0.5540 - accuracy: 0.7063 - 59s/epoch - 734ms/step\n",
            "Epoch 8/20\n",
            "80/80 - 59s - loss: 0.5430 - accuracy: 0.7244 - 59s/epoch - 738ms/step\n",
            "Epoch 9/20\n",
            "80/80 - 58s - loss: 0.5294 - accuracy: 0.7344 - 58s/epoch - 723ms/step\n",
            "Epoch 10/20\n",
            "80/80 - 60s - loss: 0.5159 - accuracy: 0.7481 - 60s/epoch - 755ms/step\n",
            "Epoch 11/20\n",
            "80/80 - 58s - loss: 0.5088 - accuracy: 0.7425 - 58s/epoch - 731ms/step\n",
            "Epoch 12/20\n",
            "80/80 - 58s - loss: 0.4836 - accuracy: 0.7675 - 58s/epoch - 725ms/step\n",
            "Epoch 13/20\n",
            "80/80 - 57s - loss: 0.4644 - accuracy: 0.7794 - 57s/epoch - 713ms/step\n",
            "Epoch 14/20\n",
            "80/80 - 55s - loss: 0.4614 - accuracy: 0.7769 - 55s/epoch - 693ms/step\n",
            "Epoch 15/20\n",
            "80/80 - 57s - loss: 0.4534 - accuracy: 0.7987 - 57s/epoch - 708ms/step\n",
            "Epoch 16/20\n",
            "80/80 - 57s - loss: 0.4547 - accuracy: 0.7881 - 57s/epoch - 718ms/step\n",
            "Epoch 17/20\n",
            "80/80 - 58s - loss: 0.4265 - accuracy: 0.8050 - 58s/epoch - 719ms/step\n",
            "Epoch 18/20\n",
            "80/80 - 56s - loss: 0.4240 - accuracy: 0.8025 - 56s/epoch - 705ms/step\n",
            "Epoch 19/20\n",
            "80/80 - 59s - loss: 0.4037 - accuracy: 0.8169 - 59s/epoch - 737ms/step\n",
            "Epoch 20/20\n",
            "80/80 - 58s - loss: 0.3899 - accuracy: 0.8219 - 58s/epoch - 725ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================================================\n",
        "# PROBLEM C4\n",
        "#\n",
        "# Build and train a classifier for the sarcasm dataset.\n",
        "# The classifier should have a final layer with 1 neuron activated by sigmoid.\n",
        "#\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# Dataset used in this problem is built by Rishabh Misra (https://rishabhmisra.github.io/publications).\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 75%\n",
        "# =======================================================================================================\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        accuracy = logs.get('accuracy') or 0.0\n",
        "        val_accuracy = logs.get('val_accuracy') or 0.0\n",
        "        if accuracy > 0.76 and val_accuracy > 0.76:\n",
        "            print(\"\\ntarget telah tercapai, stop train !!!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def solution_C4():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sarcasm.json'\n",
        "    urllib.request.urlretrieve(data_url, 'sarcasm.json')\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or test may fail\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_size = 20000\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    # YOUR CODE HERE\n",
        "    # YOUR CODE HERE\n",
        "    with open(\"./sarcasm.json\", 'r') as f:\n",
        "        datastore = json.load(f)\n",
        "\n",
        "    for item in datastore:\n",
        "        sentences.append(item['headline'])\n",
        "        labels.append(item['is_sarcastic'])\n",
        "\n",
        "    training_sentences = sentences[0:training_size]\n",
        "    testing_sentences = sentences[training_size:]\n",
        "    training_labels = labels[0:training_size]\n",
        "    testing_labels = labels[training_size:]\n",
        "\n",
        "    # Fit your tokenizer with training data\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(training_sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "    training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "    testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    training_labels = np.array(training_labels)\n",
        "    testing_labels = np.array(testing_labels)  # YOUR CODE HERE\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        tf.keras.layers.GlobalMaxPooling1D(),\n",
        "        tf.keras.layers.Dense(6, activation='relu'),\n",
        "        # YOUR CODE HERE. DO not change the last layer or test may fail\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    callbacks = CustomCallback()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    history = model.fit(training_padded,\n",
        "                        training_labels,\n",
        "                        epochs=20,\n",
        "                        callbacks=CustomCallback(),\n",
        "                        validation_data=(testing_padded, testing_labels),\n",
        "                        verbose=2)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C4()\n",
        "    model.save(\"model_C4.h5\")"
      ],
      "metadata": {
        "id": "7EY5ZD9lu9PN",
        "outputId": "bf15e7d8-2735-44bd-dd5f-e56afab721d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "625/625 - 3s - loss: 0.5777 - accuracy: 0.6909 - val_loss: 0.4561 - val_accuracy: 0.7974 - 3s/epoch - 4ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "target telah tercapai, stop train !!!\n",
            "625/625 - 3s - loss: 0.4009 - accuracy: 0.8209 - val_loss: 0.4134 - val_accuracy: 0.8126 - 3s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================================\n",
        "# PROBLEM C5\n",
        "#\n",
        "# Build and train a neural network to predict time indexed variables of\n",
        "# the multivariate house hold electric power consumption time series dataset.\n",
        "# Using a window of past 24 observations of the 7 variables, the model\n",
        "# should be trained to predict the next 24 observations of the 7 variables.\n",
        "# Use MAE as the metrics of your neural network model.\n",
        "# We provided code for normalizing the data. Please do not change the code.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is downloaded from https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption\n",
        "#\n",
        "# Desired MAE < 0.1 on the normalized dataset.\n",
        "# ============================================================================================\n",
        "\n",
        "import urllib\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# This function downloads and extracts the dataset to the directory that contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change the URL)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/household_power.zip'\n",
        "    urllib.request.urlretrieve(url, 'household_power.zip')\n",
        "    with zipfile.ZipFile('household_power.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "\n",
        "# This function normalizes the dataset using min max scaling.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    # YOUR CODE HERE\n",
        "    dataset = tf.data.Dataset.from_tensor_slices (series)\n",
        "    dataset = dataset.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch (n_past + n_future))\n",
        "    dataset = dataset.shuffle (1000)\n",
        "    dataset = dataset.map(lambda window: (window[:-n_past], window[-n_past:, :1]))\n",
        "    return dataset.batch(batch_size).prefetch(1)# YOUR CODE HERE\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def solution_C5():\n",
        "    # Downloads and extracts the dataset to the directory that contains this file.\n",
        "    download_and_extract_data()\n",
        "    # Reads the dataset from the csv.\n",
        "    df = pd.read_csv('household_power_consumption.csv', sep=',',\n",
        "                     infer_datetime_format=True, index_col='datetime', header=0)\n",
        "\n",
        "    # Number of features in the dataset. We use all features as predictors to\n",
        "    # predict all features at future time steps.\n",
        "    N_FEATURES = df.shape[1] # YOUR CODE HERE\n",
        "\n",
        "    # Normalizes the data\n",
        "    # DO NOT CHANGE THIS\n",
        "    data = df.values\n",
        "    split_time = int(len(data) * 0.5)\n",
        "    data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
        "\n",
        "    # Splits the data into training and validation sets.\n",
        "    x_train = data[:split_time] # YOUR CODE HERE\n",
        "    x_valid = data[split_time:]  # YOUR CODE HERE\n",
        "\n",
        "    # DO NOT CHANGE THIS\n",
        "    BATCH_SIZE = 32\n",
        "    N_PAST = 24 # Number of past time steps based on which future observations should be predicted\n",
        "    N_FUTURE = 24  # Number of future time steps which are to be predicted.\n",
        "    SHIFT = 1  # By how many positions the window slides to create a new window of observations.\n",
        "\n",
        "    # Code to create windowed train and validation datasets.\n",
        "    # Complete the code in windowed_dataset.\n",
        "    train_set = windowed_dataset(x_train, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)# YOUR CODE HERE\n",
        "    valid_set =  windowed_dataset(x_valid, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)# YOUR CODE HERE\n",
        "\n",
        "    # Code to define your model.\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # Whatever your first layer is, the input shape will be (N_PAST = 24, N_FEATURES = 7)\n",
        "        # YOUR CODE HERE\n",
        "        # tf.keras.layers.Dense(128, activation='relu', input_shape=[N_PAST, N_FEATURES]),\n",
        "        tf.keras.layers.LSTM(64, input_shape=(N_PAST, N_FEATURES)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(N_FUTURE * N_FEATURES),\n",
        "        tf.keras.layers.Reshape((N_FUTURE, N_FEATURES)),\n",
        "        # tf.keras.layers.LSTM(32, input_shape=(N_PAST, N_FEATURES)),\n",
        "        # tf.keras.layers.Dense(64),\n",
        "        # tf.keras.layers.Dense(168),\n",
        "        # tf.keras.layers.Reshape((N_FUTURE, N_FEATURES))\n",
        "    ])\n",
        "\n",
        "    # Code to train and compile the model\n",
        "    # YOUR CODE HERE\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_set, epochs=20, validation_data=valid_set)\n",
        "\n",
        "    return model\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C5()\n",
        "    model.save(\"model_C5.h5\")"
      ],
      "metadata": {
        "id": "arwZJXnFrUx7",
        "outputId": "bea0e9b2-22db-4879-be71-fe0da14400e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 64)                18432     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 168)               10920     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 24, 7)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29352 (114.66 KB)\n",
            "Trainable params: 29352 (114.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1349/1349 [==============================] - 57s 40ms/step - loss: 0.0482 - mae: 0.0482 - val_loss: 0.0480 - val_mae: 0.0480\n",
            "Epoch 2/20\n",
            "1349/1349 [==============================] - 41s 30ms/step - loss: 0.0439 - mae: 0.0439 - val_loss: 0.0474 - val_mae: 0.0474\n",
            "Epoch 3/20\n",
            "1349/1349 [==============================] - 50s 37ms/step - loss: 0.0435 - mae: 0.0435 - val_loss: 0.0469 - val_mae: 0.0469\n",
            "Epoch 4/20\n",
            "1349/1349 [==============================] - 48s 36ms/step - loss: 0.0433 - mae: 0.0433 - val_loss: 0.0471 - val_mae: 0.0471\n",
            "Epoch 5/20\n",
            "1349/1349 [==============================] - 41s 31ms/step - loss: 0.0430 - mae: 0.0430 - val_loss: 0.0467 - val_mae: 0.0467\n",
            "Epoch 6/20\n",
            "1349/1349 [==============================] - 42s 31ms/step - loss: 0.0429 - mae: 0.0429 - val_loss: 0.0465 - val_mae: 0.0465\n",
            "Epoch 7/20\n",
            "1349/1349 [==============================] - 48s 35ms/step - loss: 0.0426 - mae: 0.0426 - val_loss: 0.0465 - val_mae: 0.0465\n",
            "Epoch 8/20\n",
            "1349/1349 [==============================] - 48s 35ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0461 - val_mae: 0.0461\n",
            "Epoch 9/20\n",
            "1349/1349 [==============================] - 48s 35ms/step - loss: 0.0423 - mae: 0.0423 - val_loss: 0.0464 - val_mae: 0.0464\n",
            "Epoch 10/20\n",
            "1349/1349 [==============================] - 41s 30ms/step - loss: 0.0420 - mae: 0.0420 - val_loss: 0.0462 - val_mae: 0.0462\n",
            "Epoch 11/20\n",
            "1349/1349 [==============================] - 40s 29ms/step - loss: 0.0419 - mae: 0.0419 - val_loss: 0.0462 - val_mae: 0.0462\n",
            "Epoch 12/20\n",
            "1349/1349 [==============================] - 46s 34ms/step - loss: 0.0416 - mae: 0.0416 - val_loss: 0.0464 - val_mae: 0.0464\n",
            "Epoch 13/20\n",
            "1349/1349 [==============================] - 47s 35ms/step - loss: 0.0414 - mae: 0.0414 - val_loss: 0.0466 - val_mae: 0.0466\n",
            "Epoch 14/20\n",
            "1349/1349 [==============================] - 45s 33ms/step - loss: 0.0413 - mae: 0.0413 - val_loss: 0.0472 - val_mae: 0.0472\n",
            "Epoch 15/20\n",
            "1349/1349 [==============================] - 42s 31ms/step - loss: 0.0411 - mae: 0.0411 - val_loss: 0.0478 - val_mae: 0.0478\n",
            "Epoch 16/20\n",
            "1349/1349 [==============================] - 49s 36ms/step - loss: 0.0409 - mae: 0.0409 - val_loss: 0.0487 - val_mae: 0.0487\n",
            "Epoch 17/20\n",
            "1349/1349 [==============================] - 73s 54ms/step - loss: 0.0408 - mae: 0.0408 - val_loss: 0.0485 - val_mae: 0.0485\n",
            "Epoch 18/20\n",
            "1349/1349 [==============================] - 49s 36ms/step - loss: 0.0405 - mae: 0.0405 - val_loss: 0.0486 - val_mae: 0.0486\n",
            "Epoch 19/20\n",
            "1349/1349 [==============================] - 41s 31ms/step - loss: 0.0403 - mae: 0.0403 - val_loss: 0.0498 - val_mae: 0.0498\n",
            "Epoch 20/20\n",
            "1349/1349 [==============================] - 43s 32ms/step - loss: 0.0401 - mae: 0.0401 - val_loss: 0.0495 - val_mae: 0.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Selamat Datang di Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}